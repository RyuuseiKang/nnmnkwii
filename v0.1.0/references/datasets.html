

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Datasets &mdash; nnmnkwii 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/plot_directive.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Frontend" href="frontend.html" />
    <link rel="prev" title="Baseline" href="baseline.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html">
          

          
            
            <img src="../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                0.1.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../design.html">General design documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../design.html#the-underlying-design-philosophy">The underlying design philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design.html#background">Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design.html#goal">Goal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design.html#so-what-do-we-provide">So what do we provide?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design.html#design-decisions">Design decisions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design.html#development-guidelines">Development guidelines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../design_jp.html">設計ドキュメント (Japanese)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../design_jp.html#the-underlying-design-philosophy">The underlying design philosophy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design_jp.html#background">Background</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design_jp.html#goal">Goal</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design_jp.html#so-what-do-we-provide">So what do we provide?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design_jp.html#design-decisions">Design decisions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../design_jp.html#development-guidelines">Development guidelines</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html">A quick start guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Playing-with-audio-and-it’s-alignment-file">Playing with audio and it’s alignment file</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Load-wav-file">Load wav file</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Acoustic-features">Acoustic features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Load-aligment-file">Load aligment file</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Cut-silence-frames">Cut silence frames</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Linguistic-features">Linguistic features</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Playing-with-datasets">Playing with datasets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Get-example-file-sources">Get example file sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Load-data">Load data</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Utterance-wise-iteration">Utterance-wise iteration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Memory-cache-iteration">Memory cache iteration</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/00-Quick%20start%20guide.html#Frame-wise-iteration">Frame-wise iteration</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html">DNN text-to-speech synthesis (en)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Data">Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Data-specification">Data specification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#File-data-sources">File data sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Utterance-lengths">Utterance lengths</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#How-data-look-like?">How data look like?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Statistics">Statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Combine-datasets-and-normalization.">Combine datasets and normalization.</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Train">Train</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Configurations">Configurations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Training-loop">Training loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Define-models">Define models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Training-Duration-model">Training Duration model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Training-acoustic-model">Training acoustic model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Test">Test</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Parameter-generation-utilities">Parameter generation utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/01-DNN-based%20statistical%20speech%20synthesis%20%28en%29.html#Listen-generated-audio">Listen generated audio</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html">Bidirectional-LSTM based RNNs for text-to-speech synthesis (en)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Data">Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Data-specification">Data specification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#File-data-sources">File data sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Utterance-lengths">Utterance lengths</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#How-data-look-like?">How data look like?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Statistics">Statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Combine-datasets-and-normalization.">Combine datasets and normalization.</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Train">Train</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Configurations">Configurations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Trainining-loop">Trainining loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Define-models">Define models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Training-Duration-model">Training Duration model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Training-acoustic-model">Training acoustic model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Test">Test</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Parameter-generation-utilities">Parameter generation utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20%28en%29.html#Listen-generated-audio">Listen generated audio</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html">Bidirectional-LSTM based RNNs for text-to-speech synthesis with OpenJTalk (ja)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Data">Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Data-specification">Data specification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#File-data-sources">File data sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Utterance-lengths">Utterance lengths</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#How-data-look-like?">How data look like?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Statistics">Statistics</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Combine-datasets-and-normalization.">Combine datasets and normalization.</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Model">Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Train">Train</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Configurations">Configurations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Trainining-loop">Trainining loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Define-models">Define models</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Training-Duration-model">Training Duration model</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Training-acoustic-model">Training acoustic model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Test">Test</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Parameter-generation-utilities">Parameter generation utilities</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#Listen-generated-audio">Listen generated audio</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/tts/02-Bidirectional-LSTM%20based%20RNNs%20for%20speech%20synthesis%20using%20OpenJTalk%20%28ja%29.html#TTS-using-OpenJTalk-frontend">TTS using OpenJTalk frontend</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html">GMM-based voice conversion (en)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Data">Data</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Data-specification">Data specification</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#File-data-sources">File data sources</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Convert-dataset-to-arrays">Convert dataset to arrays</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#How-data-look-like?">How data look like?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Align-source-and-target-features">Align source and target features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#How-parallel-data-look-like?">How parallel data look like?</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Append-delta-features">Append delta features</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Finally,-we-get-joint-feature-matrix">Finally, we get joint feature matrix</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Model">Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Visualize-model">Visualize model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Means">Means</a></li>
<li class="toctree-l4"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Covariances">Covariances</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Test">Test</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#Listen-results">Listen results</a></li>
<li class="toctree-l3"><a class="reference internal" href="../nnmnkwii_gallery/notebooks/vc/01-GMM%20voice%20conversion%20%28en%29.html#How-different?">How different?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Package references</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="autograd.html">Autograd</a><ul>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#functional-interface">Functional interface</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.autograd.mlpg.html">nnmnkwii.autograd.mlpg</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.autograd.unit_variance_mlpg.html">nnmnkwii.autograd.unit_variance_mlpg</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.autograd.modspec.html">nnmnkwii.autograd.modspec</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="autograd.html#function-classes">Function classes</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="baseline.html">Baseline</a><ul>
<li class="toctree-l2"><a class="reference internal" href="baseline.html#module-nnmnkwii.baseline.gmm">GMM voice conversion</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#interface">Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="#implementation">Implementation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#dataset-that-supports-utterance-wise-iteration">Dataset that supports utterance-wise iteration</a></li>
<li class="toctree-l3"><a class="reference internal" href="#dataset-that-supports-frame-wise-iteration">Dataset that supports frame-wise iteration</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#builtin-data-sources">Builtin data sources</a></li>
<li class="toctree-l2"><a class="reference internal" href="#cmu-arctic-en">CMU Arctic (en)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#vctk-en">VCTK (en)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#lj-speech-en">LJ-Speech (en)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#voice-conversion-challenge-vcc-2016-en">Voice Conversion Challenge (VCC) 2016 (en)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#voice-statistics-ja">Voice statistics (ja)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jsut-ja">JSUT (ja)</a></li>
<li class="toctree-l2"><a class="reference internal" href="#jvs-ja">JVS (ja)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="frontend.html">Frontend</a><ul>
<li class="toctree-l2"><a class="reference internal" href="frontend.html#merlin-frontend">Merlin frontend</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.frontend.merlin.linguistic_features.html">nnmnkwii.frontend.merlin.linguistic_features</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.frontend.merlin.duration_features.html">nnmnkwii.frontend.merlin.duration_features</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="functions.html">Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="io.html">IO</a><ul>
<li class="toctree-l2"><a class="reference internal" href="io.html#module-nnmnkwii.io.hts">HTS IO</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.io.hts.load.html">nnmnkwii.io.hts.load</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.io.hts.load_question_set.html">nnmnkwii.io.hts.load_question_set</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.io.hts.write_audacity_labels.html">nnmnkwii.io.hts.write_audacity_labels</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.io.hts.write_textgrid.html">nnmnkwii.io.hts.write_textgrid</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="metrics.html">Evaluation metrics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="generated/nnmnkwii.metrics.melcd.html">nnmnkwii.metrics.melcd</a></li>
<li class="toctree-l2"><a class="reference internal" href="generated/nnmnkwii.metrics.mean_squared_error.html">nnmnkwii.metrics.mean_squared_error</a></li>
<li class="toctree-l2"><a class="reference internal" href="generated/nnmnkwii.metrics.lf0_mean_squared_error.html">nnmnkwii.metrics.lf0_mean_squared_error</a></li>
<li class="toctree-l2"><a class="reference internal" href="generated/nnmnkwii.metrics.vuv_error.html">nnmnkwii.metrics.vuv_error</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="paramgen.html">Parameter generation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="generated/nnmnkwii.paramgen.build_win_mats.html">nnmnkwii.paramgen.build_win_mats</a></li>
<li class="toctree-l2"><a class="reference internal" href="generated/nnmnkwii.paramgen.mlpg.html">nnmnkwii.paramgen.mlpg</a></li>
<li class="toctree-l2"><a class="reference internal" href="generated/nnmnkwii.paramgen.mlpg_grad.html">nnmnkwii.paramgen.mlpg_grad</a></li>
<li class="toctree-l2"><a class="reference internal" href="generated/nnmnkwii.paramgen.unit_variance_mlpg_matrix.html">nnmnkwii.paramgen.unit_variance_mlpg_matrix</a></li>
<li class="toctree-l2"><a class="reference internal" href="generated/nnmnkwii.paramgen.reshape_means.html">nnmnkwii.paramgen.reshape_means</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="postfilters.html">Post-filters</a><ul>
<li class="toctree-l2"><a class="reference internal" href="generated/nnmnkwii.postfilters.merlin_post_filter.html">nnmnkwii.postfilters.merlin_post_filter</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="preprocessing.html">Pre-processing</a><ul>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html#generic">Generic</a><ul>
<li class="toctree-l3"><a class="reference internal" href="preprocessing.html#utterance-wise-operations">Utterance-wise operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.mulaw.html">nnmnkwii.preprocessing.mulaw</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.inv_mulaw.html">nnmnkwii.preprocessing.inv_mulaw</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.mulaw_quantize.html">nnmnkwii.preprocessing.mulaw_quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.inv_mulaw_quantize.html">nnmnkwii.preprocessing.inv_mulaw_quantize</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.preemphasis.html">nnmnkwii.preprocessing.preemphasis</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.inv_preemphasis.html">nnmnkwii.preprocessing.inv_preemphasis</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.delta_features.html">nnmnkwii.preprocessing.delta_features</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.trim_zeros_frames.html">nnmnkwii.preprocessing.trim_zeros_frames</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.remove_zeros_frames.html">nnmnkwii.preprocessing.remove_zeros_frames</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.adjust_frame_length.html">nnmnkwii.preprocessing.adjust_frame_length</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.adjust_frame_lengths.html">nnmnkwii.preprocessing.adjust_frame_lengths</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.scale.html">nnmnkwii.preprocessing.scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.inv_scale.html">nnmnkwii.preprocessing.inv_scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.minmax_scale_params.html">nnmnkwii.preprocessing.minmax_scale_params</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.minmax_scale.html">nnmnkwii.preprocessing.minmax_scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.inv_minmax_scale.html">nnmnkwii.preprocessing.inv_minmax_scale</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.modspec.html">nnmnkwii.preprocessing.modspec</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.inv_modspec.html">nnmnkwii.preprocessing.inv_modspec</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.modspec_smoothing.html">nnmnkwii.preprocessing.modspec_smoothing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="preprocessing.html#dataset-wise-operations">Dataset-wise operations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.meanvar.html">nnmnkwii.preprocessing.meanvar</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.meanstd.html">nnmnkwii.preprocessing.meanstd</a></li>
<li class="toctree-l4"><a class="reference internal" href="generated/nnmnkwii.preprocessing.minmax.html">nnmnkwii.preprocessing.minmax</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html#f0">F0</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.preprocessing.f0.interp1d.html">nnmnkwii.preprocessing.f0.interp1d</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="preprocessing.html#alignment">Alignment</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="util.html">Utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="util.html#function-utilities">Function utilities</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.util.apply_each2d_padded.html">nnmnkwii.util.apply_each2d_padded</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.util.apply_each2d_trim.html">nnmnkwii.util.apply_each2d_trim</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="util.html#files">Files</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.util.example_label_file.html">nnmnkwii.util.example_label_file</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.util.example_audio_file.html">nnmnkwii.util.example_audio_file</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.util.example_question_file.html">nnmnkwii.util.example_question_file</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.util.example_file_data_sources_for_duration_model.html">nnmnkwii.util.example_file_data_sources_for_duration_model</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.util.example_file_data_sources_for_acoustic_model.html">nnmnkwii.util.example_file_data_sources_for_acoustic_model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="util.html#module-nnmnkwii.util.linalg">Linear algebra</a><ul>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.util.linalg.cholesky_inv.html">nnmnkwii.util.linalg.cholesky_inv</a></li>
<li class="toctree-l3"><a class="reference internal" href="generated/nnmnkwii.util.linalg.cholesky_inv_banded.html">nnmnkwii.util.linalg.cholesky_inv_banded</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Meta information</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../changelog.html">Change log</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-1-0-2021-08-11">v0.1.0 &lt;2021-08-11&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-23-2021-05-15">v0.0.23 &lt;2021-05-15&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-22-2020-12-25">v0.0.22 &lt;2020-12-25&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-21-2020-08-13">v0.0.21 &lt;2020-08-13&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-20-2020-03-02">v0.0.20 &lt;2020-03-02&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-19-2019-07-06">v0.0.19 &lt;2019-07-06&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-18-2019-05-31">v0.0.18 &lt;2019-05-31&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-17-2018-12-25">v0.0.17 &lt;2018-12-25&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-16-2018-08-23">v0.0.16 &lt;2018-08-23&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-15-2018-07-12">v0.0.15 &lt;2018-07-12&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-14-2018-06-06">v0.0.14 &lt;2018-06-06&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-13-2018-01-24">v0.0.13 &lt;2018-01-24&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-12-2018-01-04">v0.0.12 &lt;2018-01-04&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-11-2017-12-22">v0.0.11 &lt;2017-12-22&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-10-2017-12-05">v0.0.10 &lt;2017-12-05&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-9-2017-11-14">v0.0.9 &lt;2017-11-14&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-8-2017-10-25">v0.0.8 &lt;2017-10-25&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-7-2017-10-09">v0.0.7 &lt;2017-10-09&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-6-2017-10-01">v0.0.6 &lt;2017-10-01&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-5-2017-09-19">v0.0.5 &lt;2017-09-19&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-4-2017-09-01">v0.0.4 &lt;2017-09-01&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-3-2017-08-26">v0.0.3 &lt;2017-08-26&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-2-2017-08-18">v0.0.2 &lt;2017-08-18&gt;</a></li>
<li class="toctree-l2"><a class="reference internal" href="../changelog.html#v0-0-1-2017-08-14">v0.0.1 &lt;2017-08-14&gt;</a></li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nnmnkwii</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Datasets</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/references/datasets.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="module-nnmnkwii.datasets">
<span id="datasets"></span><h1>Datasets<a class="headerlink" href="#module-nnmnkwii.datasets" title="Permalink to this headline">¶</a></h1>
<p>This module provides dataset abstraction.
In this library, a dataset represents fixed-sized set of features (e.g., acoustic
features, linguistic features, duration features etc.) composed of multiple
utterances, supporting iteration and indexing.</p>
<div class="section" id="interface">
<h2>Interface<a class="headerlink" href="#interface" title="Permalink to this headline">¶</a></h2>
<p>To build dataset and represent variety of features (linguistic, duration,
acoustic, etc) in an unified way, we define couple of interfaces.</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#nnmnkwii.datasets.FileDataSource" title="nnmnkwii.datasets.FileDataSource"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FileDataSource</span></code></a></p></li>
<li><p><a class="reference internal" href="#nnmnkwii.datasets.Dataset" title="nnmnkwii.datasets.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a></p></li>
</ol>
<p>The former is an abstraction of file data sources, where we find the data and
how to process them. Any FileDataSource must implement:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">collect_files</span></code>: specifies where to find source files (wav, lab, cmp, bin, etc.).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">collect_features</span></code>: specifies how to collect features (just load from file, or do some feature extraction logic, etc).</p></li>
</ul>
<p>The later is an abstraction of dataset. Any dataset must implement
<a class="reference internal" href="#nnmnkwii.datasets.Dataset" title="nnmnkwii.datasets.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a> interface:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>: returns features (typically, two dimentional <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">__len__</span></code>: returns the size of dataset (e.g., number of utterances).</p></li>
</ul>
<p>One important point is that we use <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a> to represent features
(there might be exception though). For example,</p>
<ul class="simple">
<li><p>F0 trajecoty as <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">x</span> <span class="pre">1</span></code> array, where <code class="docutils literal notranslate"><span class="pre">T</span></code> represents number of frames.</p></li>
<li><p>Spectrogram as <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">x</span> <span class="pre">D</span></code> array, where <code class="docutils literal notranslate"><span class="pre">D</span></code> is number of feature dimention.</p></li>
<li><p>Linguistic features as <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">x</span> <span class="pre">D</span></code> array.</p></li>
</ul>
<dl class="py class">
<dt id="nnmnkwii.datasets.FileDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.</span></code><code class="sig-name descname"><span class="pre">FileDataSource</span></code><a class="reference internal" href="../_modules/nnmnkwii/datasets.html#FileDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.FileDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>File data source interface.</p>
<p>Users are expected to implement custum data source for your own data.
All file data sources must implement this interface.</p>
<dl class="py method">
<dt id="nnmnkwii.datasets.FileDataSource.collect_features">
<code class="sig-name descname"><span class="pre">collect_features</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets.html#FileDataSource.collect_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.FileDataSource.collect_features" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect features given path(s).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>args</strong> – File path or tuple of file paths</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">x</span> <span class="pre">D</span></code> features represented by 2d array.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>2darray</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nnmnkwii.datasets.FileDataSource.collect_files">
<code class="sig-name descname"><span class="pre">collect_files</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets.html#FileDataSource.collect_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.FileDataSource.collect_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect data source files</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of files, or tuple of list if you need
multiple files to collect features.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>List or tuple of list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="nnmnkwii.datasets.Dataset">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.</span></code><code class="sig-name descname"><span class="pre">Dataset</span></code><a class="reference internal" href="../_modules/nnmnkwii/datasets.html#Dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.Dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataset represents a fixed-sized set of features composed of multiple
utterances.</p>
</dd></dl>

</div>
<div class="section" id="implementation">
<h2>Implementation<a class="headerlink" href="#implementation" title="Permalink to this headline">¶</a></h2>
<p>With combination of <a class="reference internal" href="#nnmnkwii.datasets.FileDataSource" title="nnmnkwii.datasets.FileDataSource"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FileDataSource</span></code></a> and <a class="reference internal" href="#nnmnkwii.datasets.Dataset" title="nnmnkwii.datasets.Dataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Dataset</span></code></a>, we define
some dataset implementation that can be used for typical situations.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that we don’t provide special iterator implementation (e.g., mini-batch
iteration, multiprocessing, etc). Users are expected to use dataset with other
iterator implementation. For PyTorch users, we can use <a class="reference external" href="http://pytorch.org/docs/master/data.html?highlight=dataloader#torch.utils.data.DataLoader">PyTorch DataLoader</a> for
mini-batch iteration and multiprocessing. Our dataset interface is <cite>exactly</cite>
same as PyTorch’s one, so we can use PyTorch DataLoader seamlessly. See
tutorials how we can use it practically.</p>
</div>
<div class="section" id="dataset-that-supports-utterance-wise-iteration">
<h3>Dataset that supports utterance-wise iteration<a class="headerlink" href="#dataset-that-supports-utterance-wise-iteration" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="nnmnkwii.datasets.FileSourceDataset">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.</span></code><code class="sig-name descname"><span class="pre">FileSourceDataset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_data_source</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets.html#FileSourceDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.FileSourceDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Most basic dataset implementation. It supports utterance-wise iteration and
has utility (<a class="reference internal" href="#nnmnkwii.datasets.FileSourceDataset.asarray" title="nnmnkwii.datasets.FileSourceDataset.asarray"><code class="xref py py-obj docutils literal notranslate"><span class="pre">asarray</span></code></a> method) to convert dataset to an three
dimentional <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>.</p>
<p>Speech features have typically different number of time resolusion,
so we cannot simply represent dataset as an
array. To address the issue, the dataset class represents set
of features as <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">x</span> <span class="pre">T^max</span> <span class="pre">x</span> <span class="pre">D</span></code> array by padding zeros where <code class="docutils literal notranslate"><span class="pre">N</span></code> is the
number of utterances, <code class="docutils literal notranslate"><span class="pre">T^max</span></code> is maximum number of frame lenghs and <code class="docutils literal notranslate"><span class="pre">D</span></code>
is the dimention of features, respectively.</p>
<p>While this dataset loads features on-demand while indexing, if you are
dealing with relatively small dataset, it might be useful to convert it to
an array, and then do whatever with numpy/scipy functionalities.</p>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.FileSourceDataset.file_data_source">
<code class="sig-name descname"><span class="pre">file_data_source</span></code><a class="headerlink" href="#nnmnkwii.datasets.FileSourceDataset.file_data_source" title="Permalink to this definition">¶</a></dt>
<dd><p>Data source to specify 1) where to
find data to be loaded and 2) how to collect features from them.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#nnmnkwii.datasets.FileDataSource" title="nnmnkwii.datasets.FileDataSource">FileDataSource</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="nnmnkwii.datasets.FileSourceDataset.collected_files">
<code class="sig-name descname"><span class="pre">collected_files</span></code><a class="headerlink" href="#nnmnkwii.datasets.FileSourceDataset.collected_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collected files are stored.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>ndarray</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>file_data_source</strong> (<a class="reference internal" href="#nnmnkwii.datasets.FileDataSource" title="nnmnkwii.datasets.FileDataSource"><em>FileDataSource</em></a>) – File data source.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nnmnkwii.util</span> <span class="kn">import</span> <span class="n">example_file_data_sources_for_acoustic_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nnmnkwii.datasets</span> <span class="kn">import</span> <span class="n">FileSourceDataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">example_file_data_sources_for_acoustic_model</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">FileSourceDataset</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">FileSourceDataset</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">(578, 425) (578, 187)</span>
<span class="go">(675, 425) (675, 187)</span>
<span class="go">(606, 425) (606, 187)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(3, 1000, 425)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(3, 1000, 187)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="nnmnkwii.datasets.FileSourceDataset.asarray">
<code class="sig-name descname"><span class="pre">asarray</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">padded_length=None</span></em>, <em class="sig-param"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></em>, <em class="sig-param"><span class="pre">padded_length_guess=1000</span></em>, <em class="sig-param"><span class="pre">verbose=0</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets.html#FileSourceDataset.asarray"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.FileSourceDataset.asarray" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert dataset to numpy array.</p>
<p>This try to load entire dataset into a single 3d numpy array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>padded_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of maximum time frames to be expected.
If None, it is set to actual maximum time length.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype" title="(in NumPy v1.21)"><em>numpy.dtype</em></a>) – Numpy dtype.</p></li>
<li><p><strong>padded_length_guess</strong> – (int): Initial guess of max time length of
padded dataset array. Used if <code class="docutils literal notranslate"><span class="pre">padded_length</span></code> is None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Array of shape <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">x</span> <span class="pre">T^max</span> <span class="pre">x</span> <span class="pre">D</span></code> if <code class="docutils literal notranslate"><span class="pre">padded_length</span></code> is
None, otherwise <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">x</span> <span class="pre">padded_length</span> <span class="pre">x</span> <span class="pre">D</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>3d-array</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="nnmnkwii.datasets.PaddedFileSourceDataset">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.</span></code><code class="sig-name descname"><span class="pre">PaddedFileSourceDataset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file_data_source</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padded_length</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets.html#PaddedFileSourceDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.PaddedFileSourceDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Basic dataset with padding. Very similar to <a class="reference internal" href="#nnmnkwii.datasets.FileSourceDataset" title="nnmnkwii.datasets.FileSourceDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FileSourceDataset</span></code></a>,
it supports utterance-wise iteration and has
utility (<a class="reference internal" href="#nnmnkwii.datasets.PaddedFileSourceDataset.asarray" title="nnmnkwii.datasets.PaddedFileSourceDataset.asarray"><code class="xref py py-obj docutils literal notranslate"><span class="pre">asarray</span></code></a> method) to convert dataset to an three
dimentional <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.ndarray</span></code></a>.</p>
<p>The difference between <a class="reference internal" href="#nnmnkwii.datasets.FileSourceDataset" title="nnmnkwii.datasets.FileSourceDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FileSourceDataset</span></code></a> is that this returns
padded features as <code class="docutils literal notranslate"><span class="pre">T^max</span> <span class="pre">x</span> <span class="pre">D</span></code> array at <code class="docutils literal notranslate"><span class="pre">__getitem__</span></code>, while
<a class="reference internal" href="#nnmnkwii.datasets.FileSourceDataset" title="nnmnkwii.datasets.FileSourceDataset"><code class="xref py py-obj docutils literal notranslate"><span class="pre">FileSourceDataset</span></code></a> returns not-padded <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">x</span> <span class="pre">D</span></code> array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>file_data_source</strong> (<a class="reference internal" href="#nnmnkwii.datasets.FileDataSource" title="nnmnkwii.datasets.FileDataSource"><em>FileDataSource</em></a>) – File data source.</p></li>
<li><p><strong>padded_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Padded length.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.PaddedFileSourceDataset.file_data_source">
<code class="sig-name descname"><span class="pre">file_data_source</span></code><a class="headerlink" href="#nnmnkwii.datasets.PaddedFileSourceDataset.file_data_source" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#nnmnkwii.datasets.FileDataSource" title="nnmnkwii.datasets.FileDataSource">FileDataSource</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="nnmnkwii.datasets.PaddedFileSourceDataset.padded_length">
<code class="sig-name descname"><span class="pre">padded_length</span></code><a class="headerlink" href="#nnmnkwii.datasets.PaddedFileSourceDataset.padded_length" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nnmnkwii.util</span> <span class="kn">import</span> <span class="n">example_file_data_sources_for_acoustic_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nnmnkwii.datasets</span> <span class="kn">import</span> <span class="n">PaddedFileSourceDataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(3, 1000, 425)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">example_file_data_sources_for_acoustic_model</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">PaddedFileSourceDataset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="n">PaddedFileSourceDataset</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">(1000, 425) (1000, 187)</span>
<span class="go">(1000, 425) (1000, 187)</span>
<span class="go">(1000, 425) (1000, 187)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="o">.</span><span class="n">asarray</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(3, 1000, 425)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span><span class="o">.</span><span class="n">asarray</span><span class="p">()</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(3, 1000, 187)</span>
</pre></div>
</div>
<dl class="py method">
<dt id="nnmnkwii.datasets.PaddedFileSourceDataset.asarray">
<code class="sig-name descname"><span class="pre">asarray</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">dtype=&lt;class</span> <span class="pre">'numpy.float32'&gt;</span></em>, <em class="sig-param"><span class="pre">verbose=0</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets.html#PaddedFileSourceDataset.asarray"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.PaddedFileSourceDataset.asarray" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert dataset to numpy array.</p>
<p>This try to load entire dataset into a single 3d numpy array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>padded_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of maximum time frames to be expected.
If None, it is set to actual maximum time length.</p></li>
<li><p><strong>dtype</strong> (<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.dtype.html#numpy.dtype" title="(in NumPy v1.21)"><em>numpy.dtype</em></a>) – Numpy dtype.</p></li>
<li><p><strong>padded_length_guess</strong> – (int): Initial guess of max time length of
padded dataset array. Used if <code class="docutils literal notranslate"><span class="pre">padded_length</span></code> is None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Array of shape <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">x</span> <span class="pre">T^max</span> <span class="pre">x</span> <span class="pre">D</span></code> if <code class="docutils literal notranslate"><span class="pre">padded_length</span></code> is
None, otherwise <code class="docutils literal notranslate"><span class="pre">N</span> <span class="pre">x</span> <span class="pre">padded_length</span> <span class="pre">x</span> <span class="pre">D</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>3d-array</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="nnmnkwii.datasets.MemoryCacheDataset">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.</span></code><code class="sig-name descname"><span class="pre">MemoryCacheDataset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">777</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets.html#MemoryCacheDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.MemoryCacheDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>A thin dataset wrapper class that has simple cache functionality. It supports
utterance-wise iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<a class="reference internal" href="#nnmnkwii.datasets.Dataset" title="nnmnkwii.datasets.Dataset"><em>Dataset</em></a>) – Dataset implementation to wrap.</p></li>
<li><p><strong>cache_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Cache size (utterance unit).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.MemoryCacheDataset.dataset">
<code class="sig-name descname"><span class="pre">dataset</span></code><a class="headerlink" href="#nnmnkwii.datasets.MemoryCacheDataset.dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#nnmnkwii.datasets.Dataset" title="nnmnkwii.datasets.Dataset">Dataset</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="nnmnkwii.datasets.MemoryCacheDataset.cached_utterances">
<code class="sig-name descname"><span class="pre">cached_utterances</span></code><a class="headerlink" href="#nnmnkwii.datasets.MemoryCacheDataset.cached_utterances" title="Permalink to this definition">¶</a></dt>
<dd><p>Loaded utterances. Keys are utterance
indices and values are numpy arrays.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>OrderedDict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="nnmnkwii.datasets.MemoryCacheDataset.cache_size">
<code class="sig-name descname"><span class="pre">cache_size</span></code><a class="headerlink" href="#nnmnkwii.datasets.MemoryCacheDataset.cache_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Cache size.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></p>
</dd>
</dl>
</dd></dl>

<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nnmnkwii.util</span> <span class="kn">import</span> <span class="n">example_file_data_sources_for_acoustic_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nnmnkwii.datasets</span> <span class="kn">import</span> <span class="n">FileSourceDataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">example_file_data_sources_for_acoustic_model</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">FileSourceDataset</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">FileSourceDataset</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nnmnkwii.datasets</span> <span class="kn">import</span> <span class="n">MemoryCacheDataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">MemoryCacheDataset</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">MemoryCacheDataset</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="o">.</span><span class="n">cached_utterances</span>
<span class="go">OrderedDict()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="gp">...</span>
<span class="go">(578, 425) (578, 187)</span>
<span class="go">(675, 425) (675, 187)</span>
<span class="go">(606, 425) (606, 187)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">cached_utterances</span><span class="p">)</span>
<span class="go">3</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="dataset-that-supports-frame-wise-iteration">
<h3>Dataset that supports frame-wise iteration<a class="headerlink" href="#dataset-that-supports-frame-wise-iteration" title="Permalink to this headline">¶</a></h3>
<dl class="py class">
<dt id="nnmnkwii.datasets.MemoryCacheFramewiseDataset">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.</span></code><code class="sig-name descname"><span class="pre">MemoryCacheFramewiseDataset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lengths</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">777</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets.html#MemoryCacheFramewiseDataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.MemoryCacheFramewiseDataset" title="Permalink to this definition">¶</a></dt>
<dd><p>A thin dataset wrapper class that has simple cache functionality. It supports
frame-wise iteration. Different from other utterance-wise datasets, you will
need to explicitly give number of time frames for each utterance at
construction, since the class has to know the size of dataset to implement
<code class="docutils literal notranslate"><span class="pre">__len__</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you are doing random access to the dataset, please be careful that you
give sufficient large number of cache size, to avoid many file re-loading.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dataset</strong> (<a class="reference internal" href="#nnmnkwii.datasets.Dataset" title="nnmnkwii.datasets.Dataset"><em>Dataset</em></a>) – Dataset implementation to wrap.</p></li>
<li><p><strong>lengths</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – Frame lengths for each utterance.</p></li>
<li><p><strong>cache_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Cache size (utterance unit).</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.MemoryCacheFramewiseDataset.dataset">
<code class="sig-name descname"><span class="pre">dataset</span></code><a class="headerlink" href="#nnmnkwii.datasets.MemoryCacheFramewiseDataset.dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>Dataset</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#nnmnkwii.datasets.Dataset" title="nnmnkwii.datasets.Dataset">Dataset</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="nnmnkwii.datasets.MemoryCacheFramewiseDataset.cached_utterances">
<code class="sig-name descname"><span class="pre">cached_utterances</span></code><a class="headerlink" href="#nnmnkwii.datasets.MemoryCacheFramewiseDataset.cached_utterances" title="Permalink to this definition">¶</a></dt>
<dd><p>Loaded utterances.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p>OrderedDict</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="nnmnkwii.datasets.MemoryCacheFramewiseDataset.cache_size">
<code class="sig-name descname"><span class="pre">cache_size</span></code><a class="headerlink" href="#nnmnkwii.datasets.MemoryCacheFramewiseDataset.cache_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Cache size.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)">int</a></p>
</dd>
</dl>
</dd></dl>

<dl>
<dt>Examples</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nnmnkwii.util</span> <span class="kn">import</span> <span class="n">example_file_data_sources_for_acoustic_model</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nnmnkwii.datasets</span> <span class="kn">import</span> <span class="n">FileSourceDataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nnmnkwii.datasets</span> <span class="kn">import</span> <span class="n">MemoryCacheFramewiseDataset</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">example_file_data_sources_for_acoustic_model</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="o">=</span> <span class="n">FileSourceDataset</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">FileSourceDataset</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lengths</span> <span class="o">=</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">]</span> <span class="c1"># collect frame lengths</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">MemoryCacheFramewiseDataset</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="n">MemoryCacheFramewiseDataset</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">lengths</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">1859</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(425,)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>
<span class="go">(187,)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</div>
</div>
<div class="section" id="builtin-data-sources">
<h2>Builtin data sources<a class="headerlink" href="#builtin-data-sources" title="Permalink to this headline">¶</a></h2>
<p>There are a couple of builtin file data sources for typical datasets to make it
easy to work on those. With the following data source implementation,
you only need to implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>, which
defines what features you want from wav file or text (depends on data source).
If you want maximum flexibility to access dataset, you may want to implement your
own data source, instead of using bulitin ones.</p>
<p>e.g. If we are trying to extract acoustic features from wav files from
CMU Arctic, then you can write:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nnmnkwii.preprocessing</span> <span class="kn">import</span> <span class="n">trim_zeros_frames</span>
<span class="kn">from</span> <span class="nn">nnmnkwii.datasets</span> <span class="kn">import</span> <span class="n">FileSourceDataset</span>
<span class="kn">from</span> <span class="nn">nnmnkwii.datasets</span> <span class="kn">import</span> <span class="n">cmu_arctic</span>
<span class="kn">import</span> <span class="nn">pysptk</span>
<span class="kn">import</span> <span class="nn">pyworld</span>

<span class="k">class</span> <span class="nc">MyFileDataSource</span><span class="p">(</span><span class="n">cmu_arctic</span><span class="o">.</span><span class="n">WavFileDataSource</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_root</span><span class="p">,</span> <span class="n">speakers</span><span class="p">,</span> <span class="n">max_files</span><span class="o">=</span><span class="mi">100</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyFileDataSource</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">data_root</span><span class="p">,</span> <span class="n">speakers</span><span class="p">,</span> <span class="n">max_files</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">collect_features</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">path</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute mel-cepstrum given a wav file.&quot;&quot;&quot;</span>
        <span class="n">fs</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">wavfile</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
        <span class="n">f0</span><span class="p">,</span> <span class="n">timeaxis</span> <span class="o">=</span> <span class="n">pyworld</span><span class="o">.</span><span class="n">dio</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">fs</span><span class="p">,</span> <span class="n">frame_period</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
        <span class="n">f0</span> <span class="o">=</span> <span class="n">pyworld</span><span class="o">.</span><span class="n">stonemask</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f0</span><span class="p">,</span> <span class="n">timeaxis</span><span class="p">,</span> <span class="n">fs</span><span class="p">)</span>
        <span class="n">spectrogram</span> <span class="o">=</span> <span class="n">pyworld</span><span class="o">.</span><span class="n">cheaptrick</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">f0</span><span class="p">,</span> <span class="n">timeaxis</span><span class="p">,</span> <span class="n">fs</span><span class="p">)</span>
        <span class="n">spectrogram</span> <span class="o">=</span> <span class="n">trim_zeros_frames</span><span class="p">(</span><span class="n">spectrogram</span><span class="p">)</span>
        <span class="n">mc</span> <span class="o">=</span> <span class="n">pysptk</span><span class="o">.</span><span class="n">sp2mc</span><span class="p">(</span><span class="n">spectrogram</span><span class="p">,</span> <span class="n">order</span><span class="o">=</span><span class="mi">24</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.41</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mc</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">DATA_ROOT</span> <span class="o">=</span> <span class="s2">&quot;/home/ryuichi/data/cmu_arctic/&quot;</span> <span class="c1"># your data path</span>
<span class="n">data_source</span> <span class="o">=</span> <span class="n">MyFileDataSource</span><span class="p">(</span><span class="n">DATA_DIR</span><span class="p">,</span> <span class="n">speakers</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;clb&quot;</span><span class="p">],</span> <span class="n">max_files</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># 100 wav files of `clb` speaker will be collected</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">FileSourceDataset</span><span class="p">(</span><span class="n">data_source</span><span class="p">)</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">==</span> <span class="mi">100</span>

<span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">X</span><span class="p">:</span>
    <span class="c1"># do anything on acoustic features (e.g., save to disk)</span>
    <span class="k">pass</span>
</pre></div>
</div>
<p>More real examples can be found in <a class="reference external" href="https://github.com/r9y9/nnmnkwii/tree/master/tests">tests directory</a> in nnmnkwii and
tutorial notebooks in <a class="reference external" href="https://github.com/r9y9/nnmnkwii_gallery">nnmnkwii_gallery</a>.</p>
</div>
<div class="section" id="cmu-arctic-en">
<h2>CMU Arctic (en)<a class="headerlink" href="#cmu-arctic-en" title="Permalink to this headline">¶</a></h2>
<p>You can download data from <a class="reference external" href="http://festvox.org/cmu_arctic/">http://festvox.org/cmu_arctic/</a>.</p>
<dl class="py class">
<dt id="nnmnkwii.datasets.cmu_arctic.WavFileDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.cmu_arctic.</span></code><code class="sig-name descname"><span class="pre">WavFileDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">speakers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labelmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/cmu_arctic.html#WavFileDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.cmu_arctic.WavFileDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>Wav file data source for CMU Arctic dataset.</p>
<p>The data source collects wav files from CMU Arctic.
Users are expected to inherit the class and implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>
method, which defines how features are computed given a wav file path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root.</p></li>
<li><p><strong>speakers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – List of speakers to find. Supported names of speaker
are <code class="docutils literal notranslate"><span class="pre">aew</span></code>, <code class="docutils literal notranslate"><span class="pre">ahw</span></code>, <code class="docutils literal notranslate"><span class="pre">aup</span></code>, <code class="docutils literal notranslate"><span class="pre">awb</span></code>, <code class="docutils literal notranslate"><span class="pre">axb</span></code>, <code class="docutils literal notranslate"><span class="pre">bdl</span></code>,
<code class="docutils literal notranslate"><span class="pre">clb</span></code>, <code class="docutils literal notranslate"><span class="pre">eey</span></code>, <code class="docutils literal notranslate"><span class="pre">fem</span></code>, <code class="docutils literal notranslate"><span class="pre">gka</span></code>, <code class="docutils literal notranslate"><span class="pre">jmk</span></code>, <code class="docutils literal notranslate"><span class="pre">ksp</span></code>,
<code class="docutils literal notranslate"><span class="pre">ljm</span></code>, <code class="docutils literal notranslate"><span class="pre">lnh</span></code>, <code class="docutils literal notranslate"><span class="pre">rms</span></code>, <code class="docutils literal notranslate"><span class="pre">rxr</span></code>, <code class="docutils literal notranslate"><span class="pre">slp</span></code>, <code class="docutils literal notranslate"><span class="pre">slt</span></code> .</p></li>
<li><p><strong>labelmap</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a><em>[</em><em>optional</em><em>]</em>) – Dict of speaker labels. If None,
it’s assigned as incrementally (i.e., 0, 1, 2) for specified
speakers.</p></li>
<li><p><strong>max_files</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Total number of files to be collected.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.cmu_arctic.WavFileDataSource.labels">
<code class="sig-name descname"><span class="pre">labels</span></code><a class="headerlink" href="#nnmnkwii.datasets.cmu_arctic.WavFileDataSource.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Speaker labels paired with collected files.
Stored in <code class="docutils literal notranslate"><span class="pre">collect_files</span></code>. This is useful to build multi-speaker
models.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)">numpy.ndarray</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nnmnkwii.datasets.cmu_arctic.WavFileDataSource.collect_files">
<code class="sig-name descname"><span class="pre">collect_files</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/cmu_arctic.html#WavFileDataSource.collect_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.cmu_arctic.WavFileDataSource.collect_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect wav files for specific speakers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of collected wav files.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)">list</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="vctk-en">
<h2>VCTK (en)<a class="headerlink" href="#vctk-en" title="Permalink to this headline">¶</a></h2>
<p>You can download data (15GB) from <a class="reference external" href="http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html">http://homepages.inf.ed.ac.uk/jyamagis/page3/page58/page58.html</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that VCTK data sources don’t collect files for speaker <code class="docutils literal notranslate"><span class="pre">315</span></code>, since there
are no transcriptions available for <code class="docutils literal notranslate"><span class="pre">315</span></code> entries,</p>
</div>
<dl class="py class">
<dt id="nnmnkwii.datasets.vctk.TranscriptionDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.vctk.</span></code><code class="sig-name descname"><span class="pre">TranscriptionDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">speakers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['225',</span> <span class="pre">'226',</span> <span class="pre">'227',</span> <span class="pre">'228',</span> <span class="pre">'229',</span> <span class="pre">'230',</span> <span class="pre">'231',</span> <span class="pre">'232',</span> <span class="pre">'233',</span> <span class="pre">'234',</span> <span class="pre">'236',</span> <span class="pre">'237',</span> <span class="pre">'238',</span> <span class="pre">'239',</span> <span class="pre">'240',</span> <span class="pre">'241',</span> <span class="pre">'243',</span> <span class="pre">'244',</span> <span class="pre">'245',</span> <span class="pre">'246',</span> <span class="pre">'247',</span> <span class="pre">'248',</span> <span class="pre">'249',</span> <span class="pre">'250',</span> <span class="pre">'251',</span> <span class="pre">'252',</span> <span class="pre">'253',</span> <span class="pre">'254',</span> <span class="pre">'255',</span> <span class="pre">'256',</span> <span class="pre">'257',</span> <span class="pre">'258',</span> <span class="pre">'259',</span> <span class="pre">'260',</span> <span class="pre">'261',</span> <span class="pre">'262',</span> <span class="pre">'263',</span> <span class="pre">'264',</span> <span class="pre">'265',</span> <span class="pre">'266',</span> <span class="pre">'267',</span> <span class="pre">'268',</span> <span class="pre">'269',</span> <span class="pre">'270',</span> <span class="pre">'271',</span> <span class="pre">'272',</span> <span class="pre">'273',</span> <span class="pre">'274',</span> <span class="pre">'275',</span> <span class="pre">'276',</span> <span class="pre">'277',</span> <span class="pre">'278',</span> <span class="pre">'279',</span> <span class="pre">'280',</span> <span class="pre">'281',</span> <span class="pre">'282',</span> <span class="pre">'283',</span> <span class="pre">'284',</span> <span class="pre">'285',</span> <span class="pre">'286',</span> <span class="pre">'287',</span> <span class="pre">'288',</span> <span class="pre">'292',</span> <span class="pre">'293',</span> <span class="pre">'294',</span> <span class="pre">'295',</span> <span class="pre">'297',</span> <span class="pre">'298',</span> <span class="pre">'299',</span> <span class="pre">'300',</span> <span class="pre">'301',</span> <span class="pre">'302',</span> <span class="pre">'303',</span> <span class="pre">'304',</span> <span class="pre">'305',</span> <span class="pre">'306',</span> <span class="pre">'307',</span> <span class="pre">'308',</span> <span class="pre">'310',</span> <span class="pre">'311',</span> <span class="pre">'312',</span> <span class="pre">'313',</span> <span class="pre">'314',</span> <span class="pre">'316',</span> <span class="pre">'317',</span> <span class="pre">'318',</span> <span class="pre">'323',</span> <span class="pre">'326',</span> <span class="pre">'329',</span> <span class="pre">'330',</span> <span class="pre">'333',</span> <span class="pre">'334',</span> <span class="pre">'335',</span> <span class="pre">'336',</span> <span class="pre">'339',</span> <span class="pre">'340',</span> <span class="pre">'341',</span> <span class="pre">'343',</span> <span class="pre">'345',</span> <span class="pre">'347',</span> <span class="pre">'351',</span> <span class="pre">'360',</span> <span class="pre">'361',</span> <span class="pre">'362',</span> <span class="pre">'363',</span> <span class="pre">'364',</span> <span class="pre">'374',</span> <span class="pre">'376']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labelmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/vctk.html#TranscriptionDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.vctk.TranscriptionDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>Transcription data source for VCTK dataset.</p>
<p>The data source collects text transcriptions from VCTK.
Users are expected to inherit the class and implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>
method, which defines how features are computed given a transcription.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root.</p></li>
<li><p><strong>speakers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – List of speakers to find. Speaker id must be <code class="docutils literal notranslate"><span class="pre">str</span></code>.
For supported names of speaker, please refer to <code class="docutils literal notranslate"><span class="pre">available_speakers</span></code>
defined in the module.</p></li>
<li><p><strong>labelmap</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a><em>[</em><em>optional</em><em>]</em>) – Dict of speaker labels. If None,
it’s assigned as incrementally (i.e., 0, 1, 2) for specified
speakers.</p></li>
<li><p><strong>max_files</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Total number of files to be collected.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.vctk.TranscriptionDataSource.speaker_info">
<code class="sig-name descname"><span class="pre">speaker_info</span></code><a class="headerlink" href="#nnmnkwii.datasets.vctk.TranscriptionDataSource.speaker_info" title="Permalink to this definition">¶</a></dt>
<dd><p>Dict of speaker information dict. Keyes are speaker
ids (str) and each value is speaker information consists of <code class="docutils literal notranslate"><span class="pre">AGE</span></code>,
<code class="docutils literal notranslate"><span class="pre">GENDER</span></code> and <code class="docutils literal notranslate"><span class="pre">REGION</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)">dict</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="nnmnkwii.datasets.vctk.TranscriptionDataSource.labels">
<code class="sig-name descname"><span class="pre">labels</span></code><a class="headerlink" href="#nnmnkwii.datasets.vctk.TranscriptionDataSource.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Speaker labels paired with collected files.
Stored in <code class="docutils literal notranslate"><span class="pre">collect_files</span></code>. This is useful to build multi-speaker
models.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)">numpy.ndarray</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nnmnkwii.datasets.vctk.TranscriptionDataSource.collect_files">
<code class="sig-name descname"><span class="pre">collect_files</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/vctk.html#TranscriptionDataSource.collect_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.vctk.TranscriptionDataSource.collect_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect data source files</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of files, or tuple of list if you need
multiple files to collect features.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>List or tuple of list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="nnmnkwii.datasets.vctk.WavFileDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.vctk.</span></code><code class="sig-name descname"><span class="pre">WavFileDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">speakers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['225',</span> <span class="pre">'226',</span> <span class="pre">'227',</span> <span class="pre">'228',</span> <span class="pre">'229',</span> <span class="pre">'230',</span> <span class="pre">'231',</span> <span class="pre">'232',</span> <span class="pre">'233',</span> <span class="pre">'234',</span> <span class="pre">'236',</span> <span class="pre">'237',</span> <span class="pre">'238',</span> <span class="pre">'239',</span> <span class="pre">'240',</span> <span class="pre">'241',</span> <span class="pre">'243',</span> <span class="pre">'244',</span> <span class="pre">'245',</span> <span class="pre">'246',</span> <span class="pre">'247',</span> <span class="pre">'248',</span> <span class="pre">'249',</span> <span class="pre">'250',</span> <span class="pre">'251',</span> <span class="pre">'252',</span> <span class="pre">'253',</span> <span class="pre">'254',</span> <span class="pre">'255',</span> <span class="pre">'256',</span> <span class="pre">'257',</span> <span class="pre">'258',</span> <span class="pre">'259',</span> <span class="pre">'260',</span> <span class="pre">'261',</span> <span class="pre">'262',</span> <span class="pre">'263',</span> <span class="pre">'264',</span> <span class="pre">'265',</span> <span class="pre">'266',</span> <span class="pre">'267',</span> <span class="pre">'268',</span> <span class="pre">'269',</span> <span class="pre">'270',</span> <span class="pre">'271',</span> <span class="pre">'272',</span> <span class="pre">'273',</span> <span class="pre">'274',</span> <span class="pre">'275',</span> <span class="pre">'276',</span> <span class="pre">'277',</span> <span class="pre">'278',</span> <span class="pre">'279',</span> <span class="pre">'280',</span> <span class="pre">'281',</span> <span class="pre">'282',</span> <span class="pre">'283',</span> <span class="pre">'284',</span> <span class="pre">'285',</span> <span class="pre">'286',</span> <span class="pre">'287',</span> <span class="pre">'288',</span> <span class="pre">'292',</span> <span class="pre">'293',</span> <span class="pre">'294',</span> <span class="pre">'295',</span> <span class="pre">'297',</span> <span class="pre">'298',</span> <span class="pre">'299',</span> <span class="pre">'300',</span> <span class="pre">'301',</span> <span class="pre">'302',</span> <span class="pre">'303',</span> <span class="pre">'304',</span> <span class="pre">'305',</span> <span class="pre">'306',</span> <span class="pre">'307',</span> <span class="pre">'308',</span> <span class="pre">'310',</span> <span class="pre">'311',</span> <span class="pre">'312',</span> <span class="pre">'313',</span> <span class="pre">'314',</span> <span class="pre">'316',</span> <span class="pre">'317',</span> <span class="pre">'318',</span> <span class="pre">'323',</span> <span class="pre">'326',</span> <span class="pre">'329',</span> <span class="pre">'330',</span> <span class="pre">'333',</span> <span class="pre">'334',</span> <span class="pre">'335',</span> <span class="pre">'336',</span> <span class="pre">'339',</span> <span class="pre">'340',</span> <span class="pre">'341',</span> <span class="pre">'343',</span> <span class="pre">'345',</span> <span class="pre">'347',</span> <span class="pre">'351',</span> <span class="pre">'360',</span> <span class="pre">'361',</span> <span class="pre">'362',</span> <span class="pre">'363',</span> <span class="pre">'364',</span> <span class="pre">'374',</span> <span class="pre">'376']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labelmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/vctk.html#WavFileDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.vctk.WavFileDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>Transcription data source for VCTK dataset.</p>
<p>The data source collects text transcriptions from VCTK.
Users are expected to inherit the class and implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>
method, which defines how features are computed given a transcription.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root.</p></li>
<li><p><strong>speakers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – List of speakers to find. Speaker id must be <code class="docutils literal notranslate"><span class="pre">str</span></code>.
For supported names of speaker, please refer to <code class="docutils literal notranslate"><span class="pre">available_speakers</span></code>
defined in the module.</p></li>
<li><p><strong>labelmap</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a><em>[</em><em>optional</em><em>]</em>) – Dict of speaker labels. If None,
it’s assigned as incrementally (i.e., 0, 1, 2) for specified
speakers.</p></li>
<li><p><strong>max_files</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Total number of files to be collected.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.vctk.WavFileDataSource.speaker_info">
<code class="sig-name descname"><span class="pre">speaker_info</span></code><a class="headerlink" href="#nnmnkwii.datasets.vctk.WavFileDataSource.speaker_info" title="Permalink to this definition">¶</a></dt>
<dd><p>Dict of speaker information dict. Keyes are speaker
ids (str) and each value is speaker information consists of <code class="docutils literal notranslate"><span class="pre">AGE</span></code>,
<code class="docutils literal notranslate"><span class="pre">GENDER</span></code> and <code class="docutils literal notranslate"><span class="pre">REGION</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)">dict</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="nnmnkwii.datasets.vctk.WavFileDataSource.labels">
<code class="sig-name descname"><span class="pre">labels</span></code><a class="headerlink" href="#nnmnkwii.datasets.vctk.WavFileDataSource.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Speaker labels paired with collected files.
Stored in <code class="docutils literal notranslate"><span class="pre">collect_files</span></code>. This is useful to build multi-speaker
models.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)">numpy.ndarray</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nnmnkwii.datasets.vctk.WavFileDataSource.collect_files">
<code class="sig-name descname"><span class="pre">collect_files</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/vctk.html#WavFileDataSource.collect_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.vctk.WavFileDataSource.collect_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect data source files</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of files, or tuple of list if you need
multiple files to collect features.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>List or tuple of list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="lj-speech-en">
<h2>LJ-Speech (en)<a class="headerlink" href="#lj-speech-en" title="Permalink to this headline">¶</a></h2>
<p>You can download data (2.6GB) from <a class="reference external" href="https://keithito.com/LJ-Speech-Dataset/">https://keithito.com/LJ-Speech-Dataset/</a>.</p>
<dl class="py class">
<dt id="nnmnkwii.datasets.ljspeech.TranscriptionDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.ljspeech.</span></code><code class="sig-name descname"><span class="pre">TranscriptionDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">normalized</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/ljspeech.html#TranscriptionDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.ljspeech.TranscriptionDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>Transcription data source for LJSpeech dataset.</p>
<p>The data source collects text transcriptions from LJSpeech.
Users are expected to inherit the class and implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>
method, which defines how features are computed given a transcription.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root.</p></li>
<li><p><strong>normalized</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Collect normalized transcriptions or not.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.ljspeech.TranscriptionDataSource.metadata">
<code class="sig-name descname"><span class="pre">metadata</span></code><a class="headerlink" href="#nnmnkwii.datasets.ljspeech.TranscriptionDataSource.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Metadata, shapeo (<code class="docutils literal notranslate"><span class="pre">num_files</span> <span class="pre">x</span> <span class="pre">3</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)">numpy.ndarray</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nnmnkwii.datasets.ljspeech.TranscriptionDataSource.collect_files">
<code class="sig-name descname"><span class="pre">collect_files</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/ljspeech.html#TranscriptionDataSource.collect_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.ljspeech.TranscriptionDataSource.collect_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect text transcriptions.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that it returns list of transcriptions (str), not file paths.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of text transcription.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)">list</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="nnmnkwii.datasets.ljspeech.WavFileDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.ljspeech.</span></code><code class="sig-name descname"><span class="pre">WavFileDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/ljspeech.html#WavFileDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.ljspeech.WavFileDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>Wav file data source for LJSpeech dataset.</p>
<p>The data source collects wav files from LJSpeech.
Users are expected to inherit the class and implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>
method, which defines how features are computed given a wav file path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root.</p>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.ljspeech.WavFileDataSource.metadata">
<code class="sig-name descname"><span class="pre">metadata</span></code><a class="headerlink" href="#nnmnkwii.datasets.ljspeech.WavFileDataSource.metadata" title="Permalink to this definition">¶</a></dt>
<dd><p>Metadata, shape (<code class="docutils literal notranslate"><span class="pre">num_files</span> <span class="pre">x</span> <span class="pre">3</span></code>).</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)">numpy.ndarray</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nnmnkwii.datasets.ljspeech.WavFileDataSource.collect_files">
<code class="sig-name descname"><span class="pre">collect_files</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/ljspeech.html#WavFileDataSource.collect_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.ljspeech.WavFileDataSource.collect_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect wav files.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of wav files.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)">list</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="voice-conversion-challenge-vcc-2016-en">
<h2>Voice Conversion Challenge (VCC) 2016 (en)<a class="headerlink" href="#voice-conversion-challenge-vcc-2016-en" title="Permalink to this headline">¶</a></h2>
<p>You can download training data (181MB) and evaluation data (~56 MB) from <a class="reference external" href="http://datashare.is.ed.ac.uk/handle/10283/2211">http://datashare.is.ed.ac.uk/handle/10283/2211</a>.</p>
<dl class="py class">
<dt id="nnmnkwii.datasets.vcc2016.WavFileDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.vcc2016.</span></code><code class="sig-name descname"><span class="pre">WavFileDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">speakers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labelmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training_data_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">evaluation_data_root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/vcc2016.html#WavFileDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.vcc2016.WavFileDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>Wav file data source for Voice Conversion Challenge (VCC) 2016 dataset.</p>
<p>The data source collects wav files from VCC2016 dataset.
Users are expected to inherit the class and implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>
method, which defines how features are computed given a wav file path.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>VCC2016 datasets are composed of training data and evaluation data,
which can be downloaded separately. <code class="docutils literal notranslate"><span class="pre">data_root</span></code> should point to the
directory that contains both the training and evaluation data.</p>
</div>
<p>Directory structure should look like for example:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>&gt; tree -d ~/data/vcc2016/
/home/ryuichi/data/vcc2016/
├── evaluation_all
│   ├── SF1
│   ├── SF2
│   ├── SF3
│   ├── SM1
│   ├── SM2
│   ├── TF1
│   ├── TF2
│   ├── TM1
│   ├── TM2
│   └── TM3
└── vcc2016_training
    ├── SF1
    ├── SF2
    ├── SF3
    ├── SM1
    ├── SM2
    ├── TF1
    ├── TF2
    ├── TM1
    ├── TM2
    └── TM3
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root. It’s assumed that training and evaluation
data are placed at <code class="docutils literal notranslate"><span class="pre">${data_root}/vcc2016_training</span></code> and</p></li>
<li><p><strong>${data_root}/evaluation_all</strong> – </p></li>
<li><p><strong>respectively</strong> – </p></li>
<li><p><strong>default.</strong> (<em>by</em>) – </p></li>
<li><p><strong>speakers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – List of speakers to find. Supported names of speaker
are <code class="docutils literal notranslate"><span class="pre">SF1</span></code>, <code class="docutils literal notranslate"><span class="pre">SF2</span></code>, <code class="docutils literal notranslate"><span class="pre">SF3</span></code>, <code class="docutils literal notranslate"><span class="pre">SM1</span></code>, <code class="docutils literal notranslate"><span class="pre">SM2</span></code>, <code class="docutils literal notranslate"><span class="pre">TF1</span></code>, <code class="docutils literal notranslate"><span class="pre">TF2</span></code>,
<code class="docutils literal notranslate"><span class="pre">TM1</span></code>, <code class="docutils literal notranslate"><span class="pre">TM2</span></code> and <code class="docutils literal notranslate"><span class="pre">TM3</span></code>.</p></li>
<li><p><strong>labelmap</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a><em>[</em><em>optional</em><em>]</em>) – Dict of speaker labels. If None,
it’s assigned as incrementally (i.e., 0, 1, 2) for specified
speakers.</p></li>
<li><p><strong>max_files</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Total number of files to be collected.</p></li>
<li><p><strong>training_data_root</strong> – If specified, try to search training data to the
directory. If None, set to <code class="docutils literal notranslate"><span class="pre">${data_root}/vcc2016_training</span></code>.</p></li>
<li><p><strong>evaluation_data_root</strong> – If specified, try to search evaluation data to the
directory. If None, set to <code class="docutils literal notranslate"><span class="pre">${data_root}/evaluation_all</span></code>.</p></li>
<li><p><strong>training</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Whether it collects training data or not. If False,
it collects evaluation data.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.vcc2016.WavFileDataSource.labels">
<code class="sig-name descname"><span class="pre">labels</span></code><a class="headerlink" href="#nnmnkwii.datasets.vcc2016.WavFileDataSource.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Speaker labels paired with collected files.
Stored in <code class="docutils literal notranslate"><span class="pre">collect_files</span></code>. This is useful to build multi-speaker
models.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)">numpy.ndarray</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nnmnkwii.datasets.vcc2016.WavFileDataSource.collect_files">
<code class="sig-name descname"><span class="pre">collect_files</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/vcc2016.html#WavFileDataSource.collect_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.vcc2016.WavFileDataSource.collect_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect wav files for specific speakers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of collected wav files.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)">list</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="voice-statistics-ja">
<h2>Voice statistics (ja)<a class="headerlink" href="#voice-statistics-ja" title="Permalink to this headline">¶</a></h2>
<p>You can download data (~720MB) from <a class="reference external" href="https://voice-statistics.github.io/">https://voice-statistics.github.io/</a>.</p>
<dl class="py class">
<dt id="nnmnkwii.datasets.voice_statistics.TranscriptionDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.voice_statistics.</span></code><code class="sig-name descname"><span class="pre">TranscriptionDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">column</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'sentence'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/voice_statistics.html#TranscriptionDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.voice_statistics.TranscriptionDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>Transcription data source for VoiceStatistics dataset</p>
<p>Users are expected to inherit the class and implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>
method, which defines how features are computed given a transcription.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root.</p></li>
<li><p><strong>column</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – <code class="docutils literal notranslate"><span class="pre">sentense</span></code>, <code class="docutils literal notranslate"><span class="pre">yomi</span></code> or <code class="docutils literal notranslate"><span class="pre">monophone</span></code>.</p></li>
<li><p><strong>max_files</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Total number of files to be collected.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Atributes:</dt><dd><p>transcriptions (list): Transcriptions.</p>
</dd>
</dl>
<dl class="py method">
<dt id="nnmnkwii.datasets.voice_statistics.TranscriptionDataSource.collect_files">
<code class="sig-name descname"><span class="pre">collect_files</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/voice_statistics.html#TranscriptionDataSource.collect_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.voice_statistics.TranscriptionDataSource.collect_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect text transcriptions.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Note that it returns list of transcriptions (str), not file paths.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of text transcription.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)">list</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="nnmnkwii.datasets.voice_statistics.WavFileDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.voice_statistics.</span></code><code class="sig-name descname"><span class="pre">WavFileDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">speakers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labelmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">emotions</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/voice_statistics.html#WavFileDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.voice_statistics.WavFileDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>Wav file data source for Voice-statistics dataset.</p>
<p>The data source collects wav files from voice-statistics.
Users are expected to inherit the class and implement
<code class="docutils literal notranslate"><span class="pre">collect_features</span></code> method, which defines how features are computed
given a wav file path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root</p></li>
<li><p><strong>speakers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – List of speakers to load. Supported names of speaker
are <code class="docutils literal notranslate"><span class="pre">fujitou</span></code>, <code class="docutils literal notranslate"><span class="pre">tsuchiya</span></code> and <code class="docutils literal notranslate"><span class="pre">uemura</span></code>.</p></li>
<li><p><strong>labelmap</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a><em>[</em><em>optional</em><em>]</em>) – Dict of speaker labels. If None,
it’s assigned as incrementally (i.e., 0, 1, 2) for specified
speakers.</p></li>
<li><p><strong>max_files</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Total number of files to be collected.</p></li>
<li><p><strong>emotions</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – List of emotions we use. Supported names of emotions
are <code class="docutils literal notranslate"><span class="pre">angry</span></code>, <code class="docutils literal notranslate"><span class="pre">happy</span></code> and <code class="docutils literal notranslate"><span class="pre">normal</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.voice_statistics.WavFileDataSource.labels">
<code class="sig-name descname"><span class="pre">labels</span></code><a class="headerlink" href="#nnmnkwii.datasets.voice_statistics.WavFileDataSource.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>List of speaker identifiers determined by
labelmap. Stored in <code class="docutils literal notranslate"><span class="pre">collect_files</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)">numpy.ndarray</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nnmnkwii.datasets.voice_statistics.WavFileDataSource.collect_files">
<code class="sig-name descname"><span class="pre">collect_files</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/voice_statistics.html#WavFileDataSource.collect_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.voice_statistics.WavFileDataSource.collect_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect wav files for specific speakers.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of collected wav files.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)">list</a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="jsut-ja">
<h2>JSUT (ja)<a class="headerlink" href="#jsut-ja" title="Permalink to this headline">¶</a></h2>
<p>JSUT (Japanese speech corpus of Saruwatari Lab, University of Tokyo).</p>
<p>You can download data (2.7GB) from <a class="reference external" href="https://sites.google.com/site/shinnosuketakamichi/publication/jsut">https://sites.google.com/site/shinnosuketakamichi/publication/jsut</a>.</p>
<dl class="py class">
<dt id="nnmnkwii.datasets.jsut.TranscriptionDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.jsut.</span></code><code class="sig-name descname"><span class="pre">TranscriptionDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/jsut.html#TranscriptionDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.jsut.TranscriptionDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>Transcription data source for JSUT dataset.</p>
<p>The data source collects text transcriptions from JSUT.
Users are expected to inherit the class and implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>
method, which defines how features are computed given a transcription.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root.</p></li>
<li><p><strong>subsets</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – Subsets.  Supported names of subset are <code class="docutils literal notranslate"><span class="pre">basic5000</span></code>,
<code class="docutils literal notranslate"><span class="pre">countersuffix26</span></code>, <code class="docutils literal notranslate"><span class="pre">loanword128</span></code>, <code class="docutils literal notranslate"><span class="pre">onomatopee300</span></code>,
<code class="docutils literal notranslate"><span class="pre">precedent130</span></code>, <code class="docutils literal notranslate"><span class="pre">repeat500</span></code>, <code class="docutils literal notranslate"><span class="pre">travel1000</span></code>, <code class="docutils literal notranslate"><span class="pre">utparaphrase512</span></code>.
and <code class="docutils literal notranslate"><span class="pre">voiceactress100</span></code>. Default is [“basic5000”].</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="nnmnkwii.datasets.jsut.WavFileDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.jsut.</span></code><code class="sig-name descname"><span class="pre">WavFileDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">subsets</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/jsut.html#WavFileDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.jsut.WavFileDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>Wav file data source for JSUT dataset.</p>
<p>The data source collects wav files from JSUT.
Users are expected to inherit the class and implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>
method, which defines how features are computed given a wav file path.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root.</p></li>
<li><p><strong>subsets</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – Subsets.  Supported names of subset are <code class="docutils literal notranslate"><span class="pre">basic5000</span></code>,
<code class="docutils literal notranslate"><span class="pre">countersuffix26</span></code>, <code class="docutils literal notranslate"><span class="pre">loanword128</span></code>, <code class="docutils literal notranslate"><span class="pre">onomatopee300</span></code>,
<code class="docutils literal notranslate"><span class="pre">precedent130</span></code>, <code class="docutils literal notranslate"><span class="pre">repeat500</span></code>, <code class="docutils literal notranslate"><span class="pre">travel1000</span></code>, <code class="docutils literal notranslate"><span class="pre">utparaphrase512</span></code>.
and <code class="docutils literal notranslate"><span class="pre">voiceactress100</span></code>. Default is [“basic5000”].</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="jvs-ja">
<h2>JVS (ja)<a class="headerlink" href="#jvs-ja" title="Permalink to this headline">¶</a></h2>
<p>JVS: free Japanese multi-speaker voice corpus</p>
<p>You can download data from <a class="reference external" href="https://sites.google.com/site/shinnosuketakamichi/research-topics/jvs_corpus">https://sites.google.com/site/shinnosuketakamichi/research-topics/jvs_corpus</a>.</p>
<dl class="py class">
<dt id="nnmnkwii.datasets.jvs.TranscriptionDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.jvs.</span></code><code class="sig-name descname"><span class="pre">TranscriptionDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">speakers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['jvs001',</span> <span class="pre">'jvs002',</span> <span class="pre">'jvs003',</span> <span class="pre">'jvs004',</span> <span class="pre">'jvs005',</span> <span class="pre">'jvs006',</span> <span class="pre">'jvs007',</span> <span class="pre">'jvs008',</span> <span class="pre">'jvs009',</span> <span class="pre">'jvs010',</span> <span class="pre">'jvs011',</span> <span class="pre">'jvs012',</span> <span class="pre">'jvs013',</span> <span class="pre">'jvs014',</span> <span class="pre">'jvs015',</span> <span class="pre">'jvs016',</span> <span class="pre">'jvs017',</span> <span class="pre">'jvs018',</span> <span class="pre">'jvs019',</span> <span class="pre">'jvs020',</span> <span class="pre">'jvs021',</span> <span class="pre">'jvs022',</span> <span class="pre">'jvs023',</span> <span class="pre">'jvs024',</span> <span class="pre">'jvs025',</span> <span class="pre">'jvs026',</span> <span class="pre">'jvs027',</span> <span class="pre">'jvs028',</span> <span class="pre">'jvs029',</span> <span class="pre">'jvs030',</span> <span class="pre">'jvs031',</span> <span class="pre">'jvs032',</span> <span class="pre">'jvs033',</span> <span class="pre">'jvs034',</span> <span class="pre">'jvs035',</span> <span class="pre">'jvs036',</span> <span class="pre">'jvs037',</span> <span class="pre">'jvs038',</span> <span class="pre">'jvs039',</span> <span class="pre">'jvs040',</span> <span class="pre">'jvs041',</span> <span class="pre">'jvs042',</span> <span class="pre">'jvs043',</span> <span class="pre">'jvs044',</span> <span class="pre">'jvs045',</span> <span class="pre">'jvs046',</span> <span class="pre">'jvs047',</span> <span class="pre">'jvs048',</span> <span class="pre">'jvs049',</span> <span class="pre">'jvs050',</span> <span class="pre">'jvs051',</span> <span class="pre">'jvs052',</span> <span class="pre">'jvs053',</span> <span class="pre">'jvs054',</span> <span class="pre">'jvs055',</span> <span class="pre">'jvs056',</span> <span class="pre">'jvs057',</span> <span class="pre">'jvs058',</span> <span class="pre">'jvs059',</span> <span class="pre">'jvs060',</span> <span class="pre">'jvs061',</span> <span class="pre">'jvs062',</span> <span class="pre">'jvs063',</span> <span class="pre">'jvs064',</span> <span class="pre">'jvs065',</span> <span class="pre">'jvs066',</span> <span class="pre">'jvs067',</span> <span class="pre">'jvs068',</span> <span class="pre">'jvs069',</span> <span class="pre">'jvs070',</span> <span class="pre">'jvs071',</span> <span class="pre">'jvs072',</span> <span class="pre">'jvs073',</span> <span class="pre">'jvs074',</span> <span class="pre">'jvs075',</span> <span class="pre">'jvs076',</span> <span class="pre">'jvs077',</span> <span class="pre">'jvs078',</span> <span class="pre">'jvs079',</span> <span class="pre">'jvs080',</span> <span class="pre">'jvs081',</span> <span class="pre">'jvs082',</span> <span class="pre">'jvs083',</span> <span class="pre">'jvs084',</span> <span class="pre">'jvs085',</span> <span class="pre">'jvs086',</span> <span class="pre">'jvs087',</span> <span class="pre">'jvs088',</span> <span class="pre">'jvs089',</span> <span class="pre">'jvs090',</span> <span class="pre">'jvs091',</span> <span class="pre">'jvs092',</span> <span class="pre">'jvs093',</span> <span class="pre">'jvs094',</span> <span class="pre">'jvs095',</span> <span class="pre">'jvs096',</span> <span class="pre">'jvs097',</span> <span class="pre">'jvs098',</span> <span class="pre">'jvs099',</span> <span class="pre">'jvs100']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categories</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labelmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/jvs.html#TranscriptionDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.jvs.TranscriptionDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>Transcription data source for JVS dataset</p>
<p>The data source collects text transcriptions from JVS.
Users are expected to inherit the class and implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>
method, which defines how features are computed given a transcription.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root.</p></li>
<li><p><strong>speakers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – List of speakers to find. Speaker id must be <code class="docutils literal notranslate"><span class="pre">str</span></code>.
For supported names of speaker, please refer to <code class="docutils literal notranslate"><span class="pre">available_speakers</span></code>
defined in the module.</p></li>
<li><p><strong>labelmap</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a><em>[</em><em>optional</em><em>]</em>) – Dict of speaker labels. If None,
it’s assigned as incrementally (i.e., 0, 1, 2) for specified
speakers.</p></li>
<li><p><strong>max_files</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Total number of files to be collected.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.jvs.TranscriptionDataSource.speaker_info">
<code class="sig-name descname"><span class="pre">speaker_info</span></code><a class="headerlink" href="#nnmnkwii.datasets.jvs.TranscriptionDataSource.speaker_info" title="Permalink to this definition">¶</a></dt>
<dd><p>Dict of speaker information dict. Keyes are speaker
ids (str) and each value is speaker information consists of <code class="docutils literal notranslate"><span class="pre">gender</span></code>,
<code class="docutils literal notranslate"><span class="pre">minf0</span></code> and <code class="docutils literal notranslate"><span class="pre">maxf0</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)">dict</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="nnmnkwii.datasets.jvs.TranscriptionDataSource.labels">
<code class="sig-name descname"><span class="pre">labels</span></code><a class="headerlink" href="#nnmnkwii.datasets.jvs.TranscriptionDataSource.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Speaker labels paired with collected files.
Stored in <code class="docutils literal notranslate"><span class="pre">collect_files</span></code>. This is useful to build multi-speaker
models.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)">numpy.ndarray</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nnmnkwii.datasets.jvs.TranscriptionDataSource.collect_files">
<code class="sig-name descname"><span class="pre">collect_files</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/jvs.html#TranscriptionDataSource.collect_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.jvs.TranscriptionDataSource.collect_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect data source files</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of files, or tuple of list if you need
multiple files to collect features.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>List or tuple of list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="nnmnkwii.datasets.jvs.WavFileDataSource">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">nnmnkwii.datasets.jvs.</span></code><code class="sig-name descname"><span class="pre">WavFileDataSource</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data_root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">speakers</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['jvs001',</span> <span class="pre">'jvs002',</span> <span class="pre">'jvs003',</span> <span class="pre">'jvs004',</span> <span class="pre">'jvs005',</span> <span class="pre">'jvs006',</span> <span class="pre">'jvs007',</span> <span class="pre">'jvs008',</span> <span class="pre">'jvs009',</span> <span class="pre">'jvs010',</span> <span class="pre">'jvs011',</span> <span class="pre">'jvs012',</span> <span class="pre">'jvs013',</span> <span class="pre">'jvs014',</span> <span class="pre">'jvs015',</span> <span class="pre">'jvs016',</span> <span class="pre">'jvs017',</span> <span class="pre">'jvs018',</span> <span class="pre">'jvs019',</span> <span class="pre">'jvs020',</span> <span class="pre">'jvs021',</span> <span class="pre">'jvs022',</span> <span class="pre">'jvs023',</span> <span class="pre">'jvs024',</span> <span class="pre">'jvs025',</span> <span class="pre">'jvs026',</span> <span class="pre">'jvs027',</span> <span class="pre">'jvs028',</span> <span class="pre">'jvs029',</span> <span class="pre">'jvs030',</span> <span class="pre">'jvs031',</span> <span class="pre">'jvs032',</span> <span class="pre">'jvs033',</span> <span class="pre">'jvs034',</span> <span class="pre">'jvs035',</span> <span class="pre">'jvs036',</span> <span class="pre">'jvs037',</span> <span class="pre">'jvs038',</span> <span class="pre">'jvs039',</span> <span class="pre">'jvs040',</span> <span class="pre">'jvs041',</span> <span class="pre">'jvs042',</span> <span class="pre">'jvs043',</span> <span class="pre">'jvs044',</span> <span class="pre">'jvs045',</span> <span class="pre">'jvs046',</span> <span class="pre">'jvs047',</span> <span class="pre">'jvs048',</span> <span class="pre">'jvs049',</span> <span class="pre">'jvs050',</span> <span class="pre">'jvs051',</span> <span class="pre">'jvs052',</span> <span class="pre">'jvs053',</span> <span class="pre">'jvs054',</span> <span class="pre">'jvs055',</span> <span class="pre">'jvs056',</span> <span class="pre">'jvs057',</span> <span class="pre">'jvs058',</span> <span class="pre">'jvs059',</span> <span class="pre">'jvs060',</span> <span class="pre">'jvs061',</span> <span class="pre">'jvs062',</span> <span class="pre">'jvs063',</span> <span class="pre">'jvs064',</span> <span class="pre">'jvs065',</span> <span class="pre">'jvs066',</span> <span class="pre">'jvs067',</span> <span class="pre">'jvs068',</span> <span class="pre">'jvs069',</span> <span class="pre">'jvs070',</span> <span class="pre">'jvs071',</span> <span class="pre">'jvs072',</span> <span class="pre">'jvs073',</span> <span class="pre">'jvs074',</span> <span class="pre">'jvs075',</span> <span class="pre">'jvs076',</span> <span class="pre">'jvs077',</span> <span class="pre">'jvs078',</span> <span class="pre">'jvs079',</span> <span class="pre">'jvs080',</span> <span class="pre">'jvs081',</span> <span class="pre">'jvs082',</span> <span class="pre">'jvs083',</span> <span class="pre">'jvs084',</span> <span class="pre">'jvs085',</span> <span class="pre">'jvs086',</span> <span class="pre">'jvs087',</span> <span class="pre">'jvs088',</span> <span class="pre">'jvs089',</span> <span class="pre">'jvs090',</span> <span class="pre">'jvs091',</span> <span class="pre">'jvs092',</span> <span class="pre">'jvs093',</span> <span class="pre">'jvs094',</span> <span class="pre">'jvs095',</span> <span class="pre">'jvs096',</span> <span class="pre">'jvs097',</span> <span class="pre">'jvs098',</span> <span class="pre">'jvs099',</span> <span class="pre">'jvs100']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">categories</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labelmap</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_files</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/jvs.html#WavFileDataSource"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.jvs.WavFileDataSource" title="Permalink to this definition">¶</a></dt>
<dd><p>WavFile data source for JVS dataset.</p>
<p>The data source collects text transcriptions from JVS.
Users are expected to inherit the class and implement <code class="docutils literal notranslate"><span class="pre">collect_features</span></code>
method, which defines how features are computed given a transcription.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data_root</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Data root.</p></li>
<li><p><strong>speakers</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – List of speakers to find. Speaker id must be <code class="docutils literal notranslate"><span class="pre">str</span></code>.
For supported names of speaker, please refer to <code class="docutils literal notranslate"><span class="pre">available_speakers</span></code>
defined in the module.</p></li>
<li><p><strong>categories</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><em>list</em></a>) – List of categories to collect, the item should be one of
“parallel”, “nonpara” and “whisper”</p></li>
<li><p><strong>labelmap</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)"><em>dict</em></a><em>[</em><em>optional</em><em>]</em>) – Dict of speaker labels. If None,
it’s assigned as incrementally (i.e., 0, 1, 2) for specified
speakers.</p></li>
<li><p><strong>max_files</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Total number of files to be collected.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="nnmnkwii.datasets.jvs.WavFileDataSource.speaker_info">
<code class="sig-name descname"><span class="pre">speaker_info</span></code><a class="headerlink" href="#nnmnkwii.datasets.jvs.WavFileDataSource.speaker_info" title="Permalink to this definition">¶</a></dt>
<dd><p>Dict of speaker information dict. Keyes are speaker
ids (str) and each value is speaker information consists of <code class="docutils literal notranslate"><span class="pre">gender</span></code>,
<code class="docutils literal notranslate"><span class="pre">minf0</span></code> and <code class="docutils literal notranslate"><span class="pre">maxf0</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.9)">dict</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt id="nnmnkwii.datasets.jvs.WavFileDataSource.labels">
<code class="sig-name descname"><span class="pre">labels</span></code><a class="headerlink" href="#nnmnkwii.datasets.jvs.WavFileDataSource.labels" title="Permalink to this definition">¶</a></dt>
<dd><p>Speaker labels paired with collected files.
Stored in <code class="docutils literal notranslate"><span class="pre">collect_files</span></code>. This is useful to build multi-speaker
models.</p>
<dl class="field-list simple">
<dt class="field-odd">Type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.21)">numpy.ndarray</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="nnmnkwii.datasets.jvs.WavFileDataSource.collect_files">
<code class="sig-name descname"><span class="pre">collect_files</span></code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/nnmnkwii/datasets/jvs.html#WavFileDataSource.collect_files"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#nnmnkwii.datasets.jvs.WavFileDataSource.collect_files" title="Permalink to this definition">¶</a></dt>
<dd><p>Collect data source files</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of files, or tuple of list if you need
multiple files to collect features.</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p>List or tuple of list</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="frontend.html" class="btn btn-neutral float-right" title="Frontend" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="baseline.html" class="btn btn-neutral float-left" title="Baseline" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2017, Ryuichi Yamamoto.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>